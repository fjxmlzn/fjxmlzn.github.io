<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.17" />
  <meta name="author" content="Zinan Lin (林梓楠)">
  <meta name="description" content="Zinan Lin&#39;s Homepage">
  <meta name="keywords" content="Zinan Lin,PhD,Tsinghua,Top,Security,Privacy,Network,System,Computer Vision">

  <link rel="stylesheet" href="/css/highlight.min.css">
  <link rel="stylesheet" href="/css/bootstrap.min.css">
  <link rel="stylesheet" href="/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/academicons.min.css">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700|Merriweather|Roboto+Mono">
  <link rel="stylesheet" href="/css/hugo-academic.css">
  

  <link rel="alternate" href="http://zinanlin.me/index.xml" type="application/rss+xml" title="Zinan Lin&#39;s Homepage">
  <link rel="feed" href="http://zinanlin.me/index.xml" type="application/rss+xml" title="Zinan Lin&#39;s Homepage">

  <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon">
  <link rel="canonical" href="http://zinanlin.me/publication/similarity/">

  

  <title>Image Similarity Measure Based on Image Sparse Representation | Zinan Lin&#39;s Homepage</title>

</head>
<body id="top">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Zinan Lin&#39;s Homepage</a>
    </div>

    
    <div class="collapse navbar-collapse" id="#navbar-collapse-1">

      
      <ul class="nav navbar-nav navbar-right">
        
        <li class="nav-item"><a href="/#top">Home</a></li>
        
        <li class="nav-item"><a href="/#grade">Grade</a></li>
        
        <li class="nav-item"><a href="/#research">Research Projects</a></li>
        
        <li class="nav-item"><a href="/#projects">Other Projects</a></li>
        
        <li class="nav-item"><a href="/#awards">Awards</a></li>
        
        <li class="nav-item"><a href="/#contact">Contact</a></li>
        
      </ul>

    </div>
  </div>
</nav>

<div class="container">

  <div class="pub" itemscope itemtype="http://schema.org/CreativeWork">
    <div class="pub-title">
      <h1 itemprop="name">Image Similarity Measure Based on Image Sparse Representation</h1>
      <span class="pub-authors" itemprop="author">
                
                Zinan Lin, Yuantao Gu
                
            </span>
      <span class="pull-right">
                
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=http%3a%2f%2fzinanlin.me%2fpublication%2fsimilarity%2f"
         target="_blank">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Image%20Similarity%20Measure%20Based%20on%20Image%20Sparse%20Representation&amp;url=http%3a%2f%2fzinanlin.me%2fpublication%2fsimilarity%2f"
         target="_blank">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2fzinanlin.me%2fpublication%2fsimilarity%2f&amp;title=Image%20Similarity%20Measure%20Based%20on%20Image%20Sparse%20Representation"
         target="_blank">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=http%3a%2f%2fzinanlin.me%2fpublication%2fsimilarity%2f&amp;title=Image%20Similarity%20Measure%20Based%20on%20Image%20Sparse%20Representation"
         target="_blank">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Image%20Similarity%20Measure%20Based%20on%20Image%20Sparse%20Representation&amp;body=http%3a%2f%2fzinanlin.me%2fpublication%2fsimilarity%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


            </span>
    </div>

    
    
    <div class="row">
      <div class="col-sm-1"></div>
      <div class="col-sm-10">
        <div class="row">
          <div class="col-xs-12 col-sm-3 pub-row-heading">Time</div>
          <div class="col-xs-12 col-sm-9" itemprop="datePublished">
            Dec. 2014 - May 2015
          </div>
        </div>
      </div>
      <div class="col-sm-1"></div>
    </div>
    <div class="visible-xs space-below"></div>

    <div class="row" style="padding-top: 10px">
      <div class="col-sm-1"></div>
      <div class="col-sm-10">
        <div class="row">
          <div class="col-xs-12 col-sm-3 pub-row-heading" style="line-height:34px;">Links</div>
          <div class="col-xs-12 col-sm-9">

            












          </div>
        </div>
      </div>
      <div class="col-sm-1"></div>
    </div>
    <div class="visible-xs space-below"></div>

    <div class="space-below"></div>

    <div class="article-style"><small>

<h1 id="summary">Summary</h1>

<p>The goal of image similarity measure is to assess the similarity of two images in a perceptually consistent manner. It has been widely used in image copy detection, image search, object tracking and many other areas.</p>

<p>In 2006, Aharon proposed a novel dictionary learning method called K-SVD for sparse representation of signals<sup class="footnote-ref" id="fnref:k-svd"><a rel="footnote" href="#fn:k-svd">1</a></sup>. It was proved to be very effective in image denoising<sup class="footnote-ref" id="fnref:k-svd2"><a rel="footnote" href="#fn:k-svd2">2</a></sup>. Inspired by this work, I am eager to see whether the learned dictionary which contains condensed information of image&rsquo;s local structure can be used for image similarity measure.</p>

<p>Let&rsquo;s start from a brief introduction of K-SVD algorithm. Let $Y\in\mathbb{R}^{n\times N}$ contain the signals in each column, for example, each column stands for a patch of the image. Now we seek to find an overcomplete dictionary $D\in\mathbb{R}^{n\times K}$ and the coefficient matrix $X\in\mathbb{R}^{K\times N}$ such that
$$ \min_{D,X}{||Y-DX||_F^2}\text{ subject to }\forall i,||x_i||_0\leq T_0$$
for a fixed $T_0$. Here the notation $||A||_F$ stands for the Frobenius norm, defined as $||A||_F=\sqrt{\sum_{ij}^{}{A_{ij}^2}}$. The dictionary is called overcomplete because K is always larger than n. Because of that, it seems that there are an infinite number of $X$ to make $Y-DX$ equals to zero. However, we require that the number of nonzero elements in each column of $X$ can not exceed $T_0$. That is why we call it a sparse representation.</p>

<p>K-SVD solves this problem with an iterative way. Each iteration contains two stages. The first is to find $X$ subject to the optimization problem above when assuming that the dictionary $D$ is fixed. This is an NP-hard problem and the approximate solutions can be found by any pursuit algorithm such as OMP<sup class="footnote-ref" id="fnref:OMP"><a rel="footnote" href="#fn:OMP">3</a></sup>. The second is to update each column of the dictionary $D$ and its corresponding coefficient when assuming the others to be fixed using SVD algorithm. Here are two examples of K-SVD results after 10 iterations.</p>

<p><div>
    <div style="width:30%;margin:0px auto;">
        <img src="/img/projects/similarity-example.png" alt="Example" style="margin:0px;padding:0px;"/>
        <center style="font-size:65%;">Figure 1. Two Examples of Sparse Representation of Images Using K-SVD</center>
    </div>
</div>
<br /></p>

<p>As you can see, the dictionary represents the local structure of the image. Furthermore, the weight on each atom of dictionary also contains vital information. Therefore, for each representation, we define $W\in \mathbb{R}^N$ as $W_t=\frac{\sum_{k=1}^{N}X_{t,k}^2}{\sum_{i=1}^K{\sum_{k=1}^{N}X_{i,k}^2}}$ which stands for the weight of atom $t$ in the whole image. The dictionary $D$ and the weight vector $W$ are the two key values representing the feature of an image.</p>

<p>Now let&rsquo;s come to image similarity measure. Assume two images $a$ and $b$ with dictionary $D^a$, $D^b$ and weight vector $W^a$, $W^b$ respectively. The first intuition is that if two images are similar, then their dictionaries must also be similar, i.e., one&rsquo;s dictionary can be well represented by the other&rsquo;s. We formulate this idea as the first part of distance measure:
$$dis1_{a,b}=\min_Z{||Z||_0}\text{ subject to }||D^a-D^bZ||\leq \delta$$
The approximate solutions $Z^{a,b}$ can be found by pursuit algorithm such as OMP. Furthermore, the original weights of the matching columns in the dictionaries should be similar. So we introduce the second distance measure as:
$$dis2_{a,b}=\sum_{i=1}^{K}{\frac{\sum_{j=1}^K|W^a_i-W^b_j|\cdot|Z^{a,b}_{j,i}|}{\sum_{j=1}^{k}|Z^{a,b}_{j,i}|}}$$
Combining with $dis1_{a,b}$, $dis1_{b,a}$, $dis2_{a,b}$ and $dis2_{b,a}$, we finially get the similarity measure of image $a$ and $b$.</p>

<p>Based on this image similarity measure, I design image classification/clustering method and test their performance.</p>

<ul>
<li><p>Image classification. For each category in the training set, calculate its dictionary and weight vector by putting the patches of all the images in the matrix $Y$. For each test image, calculate its similarity value with the dictionary and weight vector of each category. The image&rsquo;s predicted category is the one with maximum similarity value. I tested this algorithm on three categories. Each category has ten training images and ten testing images. The average accuracy in training set is 93.3% and the average accuracy in testing set is 76.7%.</p></li>

<li><p>Image clustering. I adopt hierarchical clustering method. Suppose that there is a graph standing for the clustering scheme. Each node stands for an image and the border&rsquo;s weight is the similarity value of the images it connects. At the beginning, all the images are fully connected, which means they belong to the same category. Later, we discard the edges with lowest weight one by one. The category seperates when new connected blocks emerge. Keep doing that, and finally each category will contain only a single image. I test three categories of images. Each category contains 15 images generated by adjusting the contrast ratio, light intensity, hue, saturation and adding Gaussian noise on 5 core images. The three categories are perfectly separated when cutting off 756 edges.</p></li>
</ul>

<h1 id="reflections">Reflections</h1>

<p>It was the first research project I did in university. Looking back one and a half years later, I find that I did not do it good enough in both research method and algorithm design.</p>

<ul>
<li>I didn&rsquo;t do sufficient test on the image similarity measure and I didn&rsquo;t do the test on public dataset so that I can compare my result with others.</li>
<li>The similarity measure I proposed can resist chromatic adjusting and noise pollution. However, because the size and the direction of the image patches are determined, it cannot generate stable similarity values when facing with a scale or rotated image. Maybe I can improve the algorithm by extracting some features that are invariant to scaling, rotation and illumination changes with techniques such as SIFT as a prior step<sup class="footnote-ref" id="fnref:feature"><a rel="footnote" href="#fn:feature">4</a></sup>.</li>
<li>Image category is a high-level semantics while local structure is a low-level concept. The similarity on local structure does not necessarily indicate that the two images delineate the same thing or belong to the same category. It&rsquo;s a critical flaw in the classification method I designed and I think it can explain why I can only get a reasonable accuracy ratio in very few classes.</li>
</ul>

<h1 id="author-contributions">Author Contributions</h1>

<p>Advisor: <a href="http://gu.ee.tsinghua.edu.cn/yuantao-gu" target="_blank">Yuantao Gu</a>, Associate Professor at Tsinghua University.</p>

<p>Zinan Lin finished all the work.</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:k-svd">Aharon, Michal, Michael Elad, and Alfred Bruckstein. &ldquo;K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation.&rdquo; <i>IEEE Transactions on signal processing</i> 54.11 (2006): 4311-4322.
 <a class="footnote-return" href="#fnref:k-svd"><sup>[return]</sup></a></li>
<li id="fn:k-svd2">Elad, Michael, and Michal Aharon. &ldquo;Image denoising via sparse and redundant representations over learned dictionaries.&rdquo; <i>IEEE Transactions on Image processing</i> 15.12 (2006): 3736-3745.
 <a class="footnote-return" href="#fnref:k-svd2"><sup>[return]</sup></a></li>
<li id="fn:OMP">Chen, Sheng, Stephen A. Billings, and Wan Luo. &ldquo;Orthogonal least squares methods and their application to non-linear system identification.&rdquo; <i>International Journal of control</i> 50.5 (1989): 1873-1896.
 <a class="footnote-return" href="#fnref:OMP"><sup>[return]</sup></a></li>
<li id="fn:feature">Kang, Li-Wei, et al. &ldquo;Feature-based sparse representation for image similarity assessment.&rdquo; <i>IEEE Transactions on Multimedia</i> 13.5 (2011): 1019-1030.
 <a class="footnote-return" href="#fnref:feature"><sup>[return]</sup></a></li>
</ol>
</div>
</small></div>

  </div>

</div>
<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2016 Zinan Lin &middot; 

      Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic
      theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>

<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1260746046'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s4.cnzz.com/z_stat.php%3Fid%3D1260746046%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>

    <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js"></script>
    <script src="/js/jquery-1.12.3.min.js"></script>
    <script src="/js/bootstrap.min.js"></script>
    <script src="/js/hugo-academic.js"></script>
    

    

    
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    <script async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"></script>
    

  </body>
</html>

